# Homework 1

## Team 9:

-   Charlie Madison
-   Hrishi Mysore Harishkumar
-   Michelle Li
-   Qizhuang Huang
-   Shaun Pfister
-   Rodolfo Lerma

## Description

The data set presented contains information about the unit price of houses in New Taipei City, Taiwan.

-   **age:** The age of the house in years
-   **distance:** The distance to the nearest Mass Rapid Transit (MRT) station from the house (in meters)
-   **convenience_stores:** The number of convenience stores near the house.
-   **unit_price:** The unit price of the house, measured in 10,000 New Taiwan Dollars/Ping (1 Ping = 3.3 m2)

## Question 1:

**Load the data in R and fit a simple linear regression of unit_price onto convenience_stores.**

```{r, message = FALSE}
#Loading Libraries
library(tidyverse)
library(car)
library(leaps)
library(msm)
```

```{r}
df <- read.csv("real-estate-valuation-data-set.csv")
glimpse(df)
```

```{r}
head(df, 5)
tail(df, 5)
```

```{r}
lm_fit <- lm(unit_price ~ convenience_stores, data = df)
plot(unit_price ~ convenience_stores, data = df)
abline(lm_fit, col = "blue", lwd = 3) 
legend("topleft",legend=paste("R2 is", format(summary(lm_fit)$r.squared,digits=3)))
grid(nx = NULL, ny = NULL,
     lty = 2, col = "gray", lwd = 2)
title(main = "Regression Line (Unit Price Vs Convenience Stores)")
```

## Question 2:

**Print the summary of the model in R. In plain English, state the interpretation of the coefficient estimate associated with the predictor convenience_stores.**

```{r}
#Summary of the Regression Model
summary(lm_fit)
```

```{r}
sprintf(
    "We estimate that when there are no convenience stores near the house the average unit price would be %.2f",lm_fit$coefficients[1] * 10000
)
```

```{r}
sprintf(
    "We estimate that every unit increase in the number of convenience stores near the home is associated with a %.2f change in the average unit price",
    lm_fit$coefficients[2] * 10000
)
```

## Question 3:

**Does the model indicate a statistically significant association between convenience_stores and unit_price? Explain.**

```{r}
summary(lm_fit)$coefficients
```

```{r}
sprintf(
    "The p-value indicates there is a statistically significant association between convenience_stores and unit_price, as the p-value is very small (Pvalue %e). This p-value represents the probability convenience_store has zero impact on unit_price, which in this case is very low.",
    summary(lm_fit)$coefficients[2,4]
)
```

## Question 4:

**Create a 99% confidence interval for the coefficient associated with the predictor convenience_stores.**

```{r}
# Confidence intervals.
confint(lm_fit, parm='convenience_stores', level = 0.99)
```

Something to notice is that for each of the coefficients zero is not included in the Confidence intervals, which is another indication of the statistical significance of the predictor convenience_stores.

## Question 5:

**Fit a multiple linear regression of unit_price onto convenience_stores and distance. Evaluate the Variance Inflation Factors for this model and state whether you have any concerns regarding collinearity problems between the two predictors.**

```{r}
#Multi Linear Regression Model
lm_fit_mult <- lm(unit_price ~ convenience_stores + distance, data = df)
```

```{r}
# Collinarity.
vif(lm_fit_mult)
```

Based on the values for Variance Inflation Factors seeing above (and both being smaller than 5) there is no concern on collinearity between these 2 predictors: 
- **distance:** The distance to the nearest Mass Rapid Transit (MRT) station from the house (in meters) 
- **convenience_stores:** The number of convenience stores near the house.

## Question 6:

**Print the summary of the model in R. In plain English, state the interpretation of the coefficients associated with the predictors convenience_stores and distance.**

```{r}
summary(lm_fit_mult)
```

```{r}
sprintf(
    "We estimate that every unit increase in the number of convenience stores near the home is associated with a %.2f change in the average unit price, everything else being equal (for any value of distance)",
    lm_fit_mult$coefficients[2] * 10000
)
```

```{r}
sprintf(
    "We estimate that every unit increase (in meters) in the distance between the home and the nearest Mass Rapid Transit the home is associated with a %.2f change in the average unit price, everything else being equal (for any number of convenience stores near the home)",
    lm_fit_mult$coefficients[3] * 10000
)
```

## Question 7:

**In plain English, state the interpretation of the results of the F-test for this model.**

```{r}
summary(lm_fit_mult)$fstatistic
```

The noted High F-Test is telling us along with its low p-value that the model that we have which includes 2 predictors (convenience_stores & distance) is better than a model with only the interceptor and none other variables.

F-test checks the null hypothesis of all predictors in the model having coefficients being equal to 0 against the alternative hypothesis where at least one of the predictors in the model have coefficients statistically different from 0. So basically we are testing the hypothesis - Is our model any better than the model that includes just the intercept. Looking at the summary stats above, the p-value (F-statistic: 202.7 on 2 and 411 DF, p-value: < 2.2e-16) is very small indicating that we do have evidence that the model with 2 predictors is better. Also the F-Statistic is large confirming there is significant relationship between the response and the predictor variable.

## Question 8:

**In plain English, state the interpretation of the coefficient of determination R2 for this model (this can also be found using the summary function).**

```{r}
sprintf(
    "The interpretation of this coefficient for a multi-linear regression is that the model that includes distance and number convenience stores nearby as predictors explains %.2f percent of the variation on the unit price.",
    summary(lm_fit_mult)$adj.r.squared*100
)
```

## Question 9:

**Create a plot of unit_price vs. convenience_stores and a plot of unit_price vs. distance**

```{r}
#Looking at unit_price vs convenience_stores
plot(unit_price ~ convenience_stores, data = df)
legend("topleft",legend=paste("R2 is", format(summary(lm_fit)$r.squared,digits=3)))
abline(lm_fit, col = "purple", lwd = 3)
grid(nx = NULL, ny = NULL,
     lty = 2, col = "gray", lwd = 2)
title(main = "Unit Price Vs Convenience Stores ")
```

```{r}
#Looking at unit_price vs convenience_stores
lm_fit_1 <- lm(unit_price ~ distance, data = df)
plot(unit_price ~ distance, data = df)
legend("topleft", legend=paste("linear R2: ", format(summary(lm_fit_1)$r.squared,digits=3)))
abline(lm_fit_1, col = "purple", lwd = 3)
grid(nx = NULL, ny = NULL,
     lty = 2, col = "gray", lwd = 2)
title(main = "Unit Price Vs Distance ")
```

## Question 10:

**Based on these plots, do you believe the multiple linear regression model that we just built is appropriate for these data? Explain.**

Based on the individual behavior of the variables included in the model it seems the linear model that we built might not be best to represent the variation of the data as it is possible to see that for the variable *distance* a transformation (quadratic or logarithmic) might lead to better results.

In addition, for the variable *distance* most of the data points are concentrated at low distances to the nearest Mass Rapid Transit (MRT) station. This means most of the data used to fit the model are biased towards low distance which could make the model not very good at predicting for houses with longer distance to the nearest Mass Rapid Transit (MRT) station.

```{r}
#Looking at unit_price vs convenience_stores and a polynomial and logarithmic transformations as examples.
lm_fit_1 <- lm(unit_price ~ distance, data = df)
lm_fit_2 <- lm(unit_price ~ distance +  I(distance^2), data = df)
lm_fit_log <- lm(unit_price ~ distance +  log(distance), data = df)

plot(unit_price ~ distance, data = df)
legend("topleft", legend=paste("linear R2: ", format(summary(lm_fit_1)$r.squared,digits=3)))
legend("top",legend=paste("polynomial R2: ", format(summary(lm_fit_2)$r.squared,digits=3)))
legend("topright", legend=paste("log R2: ", format(summary(lm_fit_log)$r.squared,digits=3)))

abline(lm_fit_1, col = "purple", lwd = 3)
pred_points <- seq(0, 7000, by = 100)
lines(
    pred_points,
    predict(lm_fit_2, data.frame(distance = pred_points)),
    col = "blue",
    lwd = 3
)
lines(
    pred_points,
    predict(lm_fit_log, data.frame(distance = pred_points)),
    col = "green",
    lwd = 3
)

# Add a legend
legend("right", legend = c("linear", "polynomial", "log"), col = c("purple", "blue", "green"), lty = 2)

grid(nx = NULL, ny = NULL,
     lty = 2, col = "gray", lwd = 2)
title(main = "Unit Price Vs Distance ")
```
